{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets as GenerateDataSet ## TO GENERATE A Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement Gradient Descent\n",
    "\n",
    "def gradientDescent(inputFeaturesVect, outputVect, weightVect, learningRate, sampleSize, numIterations):\n",
    "    xTrans = inputFeaturesVect.transpose()\n",
    "    for i in range(0, numIterations):\n",
    "        hypothesis = np.dot(inputFeaturesVect, weightVect)\n",
    "        loss = hypothesis - outputVect\n",
    "        # Compute MSE loss\n",
    "        cost = np.sum(loss ** 2) / (sampleSize)\n",
    "        # Uncomment below line to track the progress of training\n",
    "        # print(\"Iteration %d | Cost: %f\" % (i, cost)) \n",
    "        # Average the gradient computed per each examaple, this is batch gradient descent.\n",
    "        gradient = np.dot(xTrans, loss) / sampleSize\n",
    "        # Update the weights vector using the gradient descent formula\n",
    "        weightVect = weightVect - learningRate * gradient\n",
    "    return weightVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref : http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression\n",
    "# Generate dataset with 100 features and 1000 samples\n",
    "inputFeatures, outputValues = GenerateDataSet.make_regression(n_samples=1000, n_features=100, n_informative=25, \n",
    "                                                              n_targets=1, bias=0.59, effective_rank=5, \n",
    "                                                              tail_strength=0.9, noise=0.99, shuffle=True, \n",
    "                                                              coef=False, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampleSize, numberOfFeatures = np.shape(inputFeatures)\n",
    "\n",
    "# Number of iterations to run Gradient Descent and rate of learning\n",
    "numIterations= 100000\n",
    "learningRate = 0.5\n",
    "\n",
    "# Initialize the weights to 1s\n",
    "weights = np.ones(numberOfFeatures)\n",
    "\n",
    "# Run gradient descent on the generated dataset\n",
    "weights = gradientDescent(inputFeatures, outputValues, weights, learningRate, sampleSize, numIterations)\n",
    "\n",
    "# Print the trained weights\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement Gradient Descent\n",
    "\n",
    "def gradientDescentMomentum(inputFeaturesVect, outputVect, weightVect, learningRate, momentum, sampleSize, numIterations):\n",
    "    xTrans = inputFeaturesVect.transpose()\n",
    "    temp,numberOfFeatures = np.shape(inputFeaturesVect)\n",
    "    prevGradient = np.zeros(numberOfFeatures);\n",
    "    for i in range(0, numIterations):\n",
    "        hypothesis = np.dot(inputFeaturesVect, weightVect)\n",
    "        loss = hypothesis - outputVect\n",
    "        # Compute MSE loss\n",
    "        cost = np.sum(loss ** 2) / (sampleSize)\n",
    "        # Uncomment below line to track the progress of training\n",
    "        print(\"Iteration %d | Cost: %f\" % (i, cost)) \n",
    "        # Average the gradient computed per each examaple, this is batch gradient descent.\n",
    "        gradient = momentum*prevGradient + np.dot(xTrans, loss) / sampleSize\n",
    "        # Update the weights vector using the gradient descent formula\n",
    "        weightVect = weightVect - learningRate * gradient\n",
    "    return weightVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize, numberOfFeatures = np.shape(inputFeatures)\n",
    "\n",
    "# Number of iterations to run Gradient Descent and rate of learning\n",
    "numIterations= 100000\n",
    "learningRate = 0.5\n",
    "momentum = 0.9\n",
    "\n",
    "# Initialize the weights to 1s\n",
    "weights = np.ones(numberOfFeatures)\n",
    "\n",
    "# Run gradient descent on the generated dataset\n",
    "weights = gradientDescentMomentum(inputFeatures, outputValues, weights, learningRate,momentum, sampleSize, numIterations)\n",
    "\n",
    "# Print the trained weights\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
